{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://LAPTOP-D4GN0MQF:4040\n",
       "SparkContext available as 'sc' (version = 2.3.0, master = local[*], app id = local-1564662866818)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    }
   ],
   "source": [
    "println(\"Start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\r\n",
       "import org.apache.spark.sql.expressions.Window\r\n",
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://LAPTOP-D4GN0MQF:4040\n",
       "SparkContext available as 'sc' (version = 2.3.0, master = local[*], app id = local-1566400781689)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "left: org.apache.spark.sql.DataFrame = [id: int, left: string]\r\n",
       "right: org.apache.spark.sql.DataFrame = [id: int, right: string]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val left = Seq((0, \"zero\"), (1, \"one\")).toDF(\"id\", \"left\")\n",
    "val right = Seq((0, \"zero\"), (2, \"two\"), (3, \"three\")).toDF(\"id\", \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|left|\n",
      "+---+----+\n",
      "|  0|zero|\n",
      "|  1| one|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "left.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|right|\n",
      "+---+-----+\n",
      "|  0| zero|\n",
      "|  2|  two|\n",
      "|  3|three|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "right.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+\n",
      "| id|left|right|\n",
      "+---+----+-----+\n",
      "|  0|zero| zero|\n",
      "+---+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "left.join(right, \"id\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Join and rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfTries: org.apache.spark.sql.DataFrame = [try: string, try_day: string]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfTries = Seq(\n",
    "  (\"Try 1\", \"2018-08-01\"),\n",
    "  (\"Try 2\", \"2018-09-01\"),\n",
    "  (\"Try 3\", \"2018-10-01\"),\n",
    "  (\"Try 4\", \"2018-10-02\")\n",
    ").toDF(\"try\", \"try_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfContracts: org.apache.spark.sql.DataFrame = [contract: string, contract_day: string]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfContracts = Seq(\n",
    "  (\"contract 1\", \"2018-08-01\"),\n",
    "  (\"contract 2\", \"2018-09-02\"),\n",
    "  (\"contract 3\", \"2018-10-01\")\n",
    ").toDF(\"contract\", \"contract_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01 09:53:25 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "+-----+----------+----------+-----------+----+----------+------------+\n",
      "|  try|   try_day|    try_ts|prev_try_ts|rank|  contract|contract_day|\n",
      "+-----+----------+----------+-----------+----+----------+------------+\n",
      "|Try 1|2018-08-01|1533092400| 1535770800|   1|contract 1|  2018-08-01|\n",
      "|Try 2|2018-09-01|1535770800| 1538362800|   1|contract 2|  2018-09-02|\n",
      "|Try 3|2018-10-01|1538362800| 1538449200|   2|      null|        null|\n",
      "|Try 4|2018-10-02|1538449200|       null|   1|contract 3|  2018-10-01|\n",
      "+-----+----------+----------+-----------+----+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfTries.\n",
    "    withColumn(\"try_ts\", unix_timestamp($\"try_day\", \"yyyy-MM-dd\")).\n",
    "    withColumn(\"prev_try_ts\", lead($\"try_ts\",1).over(Window.orderBy($\"try\"))).\n",
    "    withColumn(\"rank\", when(\n",
    "        $\"prev_try_ts\".isNull || abs($\"try_ts\" - $\"prev_try_ts\") > 10 * 24 * 3600,\n",
    "        1\n",
    "    ).otherwise(2)\n",
    ").\n",
    "join(\n",
    "   dfContracts,\n",
    "   $\"rank\" === 1 && abs($\"try_ts\" - unix_timestamp($\"contract_day\", \"yyyy-MM-dd\")) <= 2 * 24 * 3600,\n",
    "        \"left_outer\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
